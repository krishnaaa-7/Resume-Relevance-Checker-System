{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "mount_file_id": "1ASyH4GEsoZs1hSD4_SG-TEqB-wbjUFKC",
      "authorship_tag": "ABX9TyMHxsvzuY87sqaDhCWyxY8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "69109b2ec494458a9fe57b25590614b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e49ae7b2702547e1b5bcf131fd9c32f6",
              "IPY_MODEL_7b25ba1bd9ba426ab968ccbafe4261c1",
              "IPY_MODEL_a0bbfe40802e4145904bd437d42092b2",
              "IPY_MODEL_53d40c2182534107bb8145af09e3e19e",
              "IPY_MODEL_e1c01de9feca41edacd2c9b58fc0f457"
            ],
            "layout": "IPY_MODEL_8c09c5b571c44b8185e94f9b28fd2936"
          }
        },
        "e49ae7b2702547e1b5bcf131fd9c32f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d17571b1e744429e7cc2e28663b6dc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_2f2e8af27c5a4c2188bb3b18bfc72cec",
            "value": "<h2>âœ¨ Resume Relevance Checker</h2>"
          }
        },
        "7b25ba1bd9ba426ab968ccbafe4261c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c19b2d931f44683b91ec3ed2b17bbb3",
              "IPY_MODEL_de340f3cf4c54d23847e68524c531600",
              "IPY_MODEL_aff0aee360ff47689edb7ee2a0b297a6"
            ],
            "layout": "IPY_MODEL_d4e737467e31454e8c736049852a4a26"
          }
        },
        "a0bbfe40802e4145904bd437d42092b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_212729b3d084452c86e75f6d32f60a9a"
            ],
            "layout": "IPY_MODEL_c4bb7bd61e5347d2a7b0440a8b5463ff"
          }
        },
        "53d40c2182534107bb8145af09e3e19e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1a53f09a22b42b0b97f473860c82af7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_75ca5489ca354b818a615ee1e93b8aa2",
            "value": "<h3>Results:</h3>"
          }
        },
        "e1c01de9feca41edacd2c9b58fc0f457": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_faa83d98a0394b4bb9e5c72130dd8a94",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Processing files and evaluating...\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Token indices sequence length is longer than the specified maximum sequence length for this model (1280 > 512). Running this sequence through the model will result in indexing errors\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<h4>ðŸ“Š Evaluation Results</h4>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p><b>Final Score:</b> 59.67% (Medium)</p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p><b>Hard Match Score:</b> 60.42%</p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<p><b>Semantic Similarity:</b> 58.55%</p>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<h4>ðŸš¨ Missing Required Skills:</h4>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<ul><li>c</li><li>nlp</li><li>spark</li></ul>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<h4>ðŸ’¡ Suggested Improvements:</h4>"
                },
                "metadata": {}
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<IPython.core.display.HTML object>",
                  "text/html": "<div style='white-space:pre-wrap;'>Expense Tracker & Automation Tools - Excel VB â€¢ Built user form-based Expense Tracker to categorize, sum, and visualize user-entered expenditures â€¢ Developed macros to auto-fill sequences, remove blank rows, and save workbooks with dynamically generated timestamps â€¢ Demonstrated file automation, data cleanup, and user interactionâ€”all within a concise Excel VBA-enabled project Vrinda Store Data Analysis | Excel| Link April-2023 â€¢ Analysed the 2024 annual sales report Store Vrinda Share to identify trends, understand customer behaviour and generate actionable insights for increasing sales in the upcoming year. â€¢ Cleaned and pre-processed raw data to ensure accuracy and consistency using Excel. â€¢ Performed data cleaning by handling 11% missing values and ensuring data consistency for accurate insights. â€¢ Market trend analysis-Understanding popular TV models having 4.1 rating and price trend. â€¢ Price comparison Missing skills (from hard match): c, nlp, spark</div>"
                },
                "metadata": {}
              }
            ]
          }
        },
        "8c09c5b571c44b8185e94f9b28fd2936": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid lightgray",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "20px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "20px",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "99d17571b1e744429e7cc2e28663b6dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f2e8af27c5a4c2188bb3b18bfc72cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c19b2d931f44683b91ec3ed2b17bbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4901a8f0543247d786842f3ff70b74e2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_00bb44e7c0ad40dea6f9d4b6768f4af7",
            "value": "Upload Files:"
          }
        },
        "de340f3cf4c54d23847e68524c531600": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf,.docx,.txt",
            "button_style": "primary",
            "data": [
              null
            ],
            "description": "Upload Resume",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "file",
            "layout": "IPY_MODEL_cb1e9aa7f1e04f7a927cdbee42669ef2",
            "metadata": [
              {
                "name": "Resume - 5.pdf",
                "type": "application/pdf",
                "size": 130399,
                "lastModified": 1758387048735
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_de4beec460474c21a902d363e366153b"
          }
        },
        "aff0aee360ff47689edb7ee2a0b297a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FileUploadModel",
          "model_module_version": "1.5.0",
          "state": {
            "_counter": 1,
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FileUploadModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "FileUploadView",
            "accept": ".pdf,.docx,.txt",
            "button_style": "primary",
            "data": [
              null
            ],
            "description": "Upload Job Description",
            "description_tooltip": null,
            "disabled": false,
            "error": "",
            "icon": "file",
            "layout": "IPY_MODEL_997538fee1344af78c7a8ff13cfd78d5",
            "metadata": [
              {
                "name": "sample_jd_2 (1).pdf",
                "type": "application/pdf",
                "size": 188837,
                "lastModified": 1758387090099
              }
            ],
            "multiple": false,
            "style": "IPY_MODEL_dccf70f8f11842db80565002936ce2a8"
          }
        },
        "d4e737467e31454e8c736049852a4a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "212729b3d084452c86e75f6d32f60a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "success",
            "description": "Evaluate Resume",
            "disabled": false,
            "icon": "play",
            "layout": "IPY_MODEL_791f3fd50d7543d09e18fb3866e9ed46",
            "style": "IPY_MODEL_405867790bee434780fd147096b44c54",
            "tooltip": "Click to evaluate"
          }
        },
        "c4bb7bd61e5347d2a7b0440a8b5463ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1a53f09a22b42b0b97f473860c82af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75ca5489ca354b818a615ee1e93b8aa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4901a8f0543247d786842f3ff70b74e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00bb44e7c0ad40dea6f9d4b6768f4af7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb1e9aa7f1e04f7a927cdbee42669ef2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de4beec460474c21a902d363e366153b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "997538fee1344af78c7a8ff13cfd78d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dccf70f8f11842db80565002936ce2a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "791f3fd50d7543d09e18fb3866e9ed46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "405867790bee434780fd147096b44c54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "faa83d98a0394b4bb9e5c72130dd8a94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnaaa-7/Resume-Relevance-Checker-System/blob/main/Resume_Relevance_Checker_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sGORagWiInuC"
      },
      "outputs": [],
      "source": [
        "!pip install -q sentence-transformers transformers pdfplumber python-docx docx2txt rapidfuzz faiss-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import docx2txt\n",
        "from rapidfuzz import fuzz, process\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline"
      ],
      "metadata": {
        "id": "z67NWrMZItWX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Utilities: text extraction\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    texts = []\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            txt = page.extract_text()\n",
        "            if txt:\n",
        "                texts.append(txt)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def extract_text_from_docx(path: str) -> str:\n",
        "    return docx2txt.process(path)\n",
        "\n",
        "def extract_text(path: str) -> str:\n",
        "    ext = path.lower().split('.')[-1]\n",
        "    if ext == 'pdf':\n",
        "        return extract_text_from_pdf(path)\n",
        "    elif ext in ('docx', 'doc'):\n",
        "        return extract_text_from_docx(path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type: \" + ext)\n"
      ],
      "metadata": {
        "id": "DcZibmGOIyrP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Preprocessing\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = re.sub(r'\\r\\n', '\\n', text)\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "C4NrCiHVJGBC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Lightweight section extraction heuristics (Skills / Education / Projects)\n",
        "SECTION_HEADINGS = [\n",
        "    r'\\bskills\\b', r'\\btechnical skills\\b', r'\\bprogramming skills\\b',\n",
        "    r'\\beducation\\b', r'\\bprojects\\b', r'\\bexperience\\b', r'\\bcertifications\\b'\n",
        "]\n",
        "\n",
        "def find_sections(text: str) -> Dict[str,str]:\n",
        "    # Very simple heuristic: split by common headings\n",
        "    # returns dict of heading -> content\n",
        "    lower = text.lower()\n",
        "    # find indices of headings\n",
        "    headings_pos = []\n",
        "    for h in SECTION_HEADINGS:\n",
        "        for m in re.finditer(h, lower):\n",
        "            headings_pos.append((m.start(), m.group()))\n",
        "    headings_pos.sort()\n",
        "    sections = {}\n",
        "    if not headings_pos:\n",
        "        sections['full'] = text\n",
        "        return sections\n",
        "    # boundaries\n",
        "    for i, (pos, head) in enumerate(headings_pos):\n",
        "        start = pos\n",
        "        end = headings_pos[i+1][0] if i+1 < len(headings_pos) else len(text)\n",
        "        name = re.sub(r'[^a-z ]','', head).strip()\n",
        "        content = text[start:end]\n",
        "        sections[name] = content\n",
        "    # add full text\n",
        "    sections['full'] = text\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "KpYgq5TbJMza"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Skill extraction by matching against a skill-list (can be extended)\n",
        "# We'll provide a default skill list; in production load from curated DB.\n",
        "DEFAULT_SKILLS = [\n",
        "    \"python\",\"java\",\"c++\",\"c\",\"c#\",\"sql\",\"nosql\",\"mongodb\",\"postgresql\",\"mysql\",\n",
        "    \"tensorflow\",\"pytorch\",\"keras\",\"scikit-learn\",\"transformers\",\"nlp\",\"computer vision\",\n",
        "    \"cv\",\"docker\",\"kubernetes\",\"aws\",\"azure\",\"gcp\",\"rest api\",\"fastapi\",\"flask\",\n",
        "    \"git\",\"linux\",\"spark\",\"hadoop\",\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\n",
        "    \"react\",\"nodejs\",\"javascript\",\"html\",\"css\",\"bash\",\"shell\",\"opencv\"\n",
        "]\n",
        "\n",
        "def extract_skills_from_text(text: str, skill_list: List[str]=None) -> List[str]:\n",
        "    if skill_list is None:\n",
        "        skill_list = DEFAULT_SKILLS\n",
        "    found = set()\n",
        "    lower = text.lower()\n",
        "    for skill in skill_list:\n",
        "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', lower):\n",
        "            found.add(skill)\n",
        "    # also capture candidate-defined ones using fuzzy token matching\n",
        "    tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', text)\n",
        "    for tok in set(tokens):\n",
        "        # Use try-except to handle potential issues with extractOne returning more than 2 values\n",
        "        try:\n",
        "            match, score = process.extractOne(tok.lower(), skill_list, scorer=fuzz.partial_ratio)\n",
        "            if score and score >= 90:\n",
        "                found.add(match)\n",
        "        except ValueError:\n",
        "            # If extractOne returns more than 2 values, skip this token or handle as needed\n",
        "            continue\n",
        "    return sorted(found)"
      ],
      "metadata": {
        "id": "o7Z4n4nlJRq6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7) JD parsing: heuristics to pull required and nice-to-have\n",
        "def parse_jd(jd_text: str) -> Dict[str, List[str]]:\n",
        "    jd_lower = jd_text.lower()\n",
        "    # Try to find \"must have / required\" lists\n",
        "    required = []\n",
        "    nice = []\n",
        "    # Common patterns\n",
        "    required_patterns = [r'(must have|must|required|requirements:|required skills:|responsibilities:)',]\n",
        "    nice_patterns = [r'(nice to have|good to have|preferred|preferred qualifications)',]\n",
        "    # split lines and attempt to classify lines\n",
        "    lines = [l.strip() for l in jd_text.splitlines() if l.strip()]\n",
        "    cur_bucket = None\n",
        "    for line in lines:\n",
        "        ll = line.lower()\n",
        "        if any(p in ll for p in required_patterns):\n",
        "            cur_bucket = 'required'\n",
        "            continue\n",
        "        if any(p in ll for p in nice_patterns):\n",
        "            cur_bucket = 'nice'\n",
        "            continue\n",
        "        # bullets or comma-separated\n",
        "        if line.startswith('-') or line.startswith('*') or len(line.split())<12:\n",
        "            bucket = cur_bucket if cur_bucket else 'required'  # default assume required\n",
        "            if bucket == 'required':\n",
        "                required.append(line.strip('-* ').strip())\n",
        "            else:\n",
        "                nice.append(line.strip('-* ').strip())\n",
        "        else:\n",
        "            # longer sentences, also try to extract skills using our skill list\n",
        "            # fallback: gather any skill words\n",
        "            pass\n",
        "    # additionally, extract skills from whole JD text\n",
        "    jd_skills = extract_skills_from_text(jd_text)\n",
        "    # if we couldn't parse bullets, use jd_skills as required\n",
        "    if not required and jd_skills:\n",
        "        required = jd_skills\n",
        "    # rudimentary cleaning (split comma lists)\n",
        "    def split_items(items):\n",
        "        out=[]\n",
        "        for it in items:\n",
        "            for part in re.split(r'[;,/]| or |\\band\\b', it):\n",
        "                p = part.strip()\n",
        "                if p:\n",
        "                    out.append(p)\n",
        "        return list(dict.fromkeys(out))\n",
        "    required = split_items(required)\n",
        "    nice = split_items(nice)\n",
        "    return {\"required\": required, \"nice_to_have\": nice, \"skills\": jd_skills}\n"
      ],
      "metadata": {
        "id": "62UbWEQdJe5E"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8) Embeddings setup (SentenceTransformers)\n",
        "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    return embed_model.encode(text, convert_to_tensor=True)\n"
      ],
      "metadata": {
        "id": "a0abc_3HJmRQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 9) Matching & scoring\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_sim_vec(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    if np.all(a==0) or np.all(b==0):\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
        "\n",
        "def hard_match_score(jd_required: List[str], resume_text: str) -> Tuple[float, List[str], List[Tuple[str,float]]]:\n",
        "    \"\"\"\n",
        "    Returns: score between 0-100, list of missing required items, list of (matched_item, score)\n",
        "    We use fuzzy matching for resilience.\n",
        "    \"\"\"\n",
        "    resume_lower = resume_text.lower()\n",
        "    matched = []\n",
        "    missing = []\n",
        "    matched_scores = []\n",
        "    for req in jd_required:\n",
        "        req_clean = req.strip().lower()\n",
        "        # exact word presence?\n",
        "        if re.search(r'\\b' + re.escape(req_clean) + r'\\b', resume_lower):\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, 100.0))\n",
        "            continue\n",
        "        # fuzzy search for tokens\n",
        "        tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', req_clean)\n",
        "        # take highest fuzzy match across resume text tokens\n",
        "        score = 0\n",
        "        for tok in tokens:\n",
        "            s = fuzz.partial_ratio(tok, resume_lower)\n",
        "            if s>score:\n",
        "                score = s\n",
        "        if score >= 75:\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, float(score)))\n",
        "        else:\n",
        "            missing.append(req)\n",
        "    # Score = matched_count / total_required * 100, weighted by fuzzy score\n",
        "    if not jd_required:\n",
        "        return 0.0, [], []\n",
        "    weighted = 0.0\n",
        "    for m, sc in matched_scores:\n",
        "        weighted += sc/100.0\n",
        "    hard_score = (weighted / len(jd_required)) * 100.0\n",
        "    return round(hard_score,2), missing, matched_scores\n",
        "\n",
        "def semantic_score(jd_text: str, resume_text: str) -> float:\n",
        "    # embed full jd and resume\n",
        "    e_jd = embed_model.encode(jd_text, convert_to_tensor=True)\n",
        "    e_res = embed_model.encode(resume_text, convert_to_tensor=True)\n",
        "    sim = util.pytorch_cos_sim(e_jd, e_res).item()\n",
        "    return round(sim * 100.0, 2)  # convert 0-1 -> 0-100\n"
      ],
      "metadata": {
        "id": "m4tOadetJwPh"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10) Weighted scoring formula and verdict\n",
        "def compute_final_score(hard: float, semantic: float, weights: Dict[str,float]=None):\n",
        "    # default weights: hard 0.6, semantic 0.4\n",
        "    if weights is None:\n",
        "        weights = {\"hard\": 0.6, \"semantic\": 0.4}\n",
        "    final = hard*weights['hard'] + semantic*weights['semantic']\n",
        "    return round(final, 2)\n",
        "\n",
        "def verdict_from_score(score: float):\n",
        "    if score >= 75:\n",
        "        return \"High\"\n",
        "    elif score >= 50:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\""
      ],
      "metadata": {
        "id": "9DUz62oWJ3FG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 11) LLM-based improvement suggestion (uses HF pipeline; small model by default)\n",
        "# Note: you can swap model name to a larger LLM if needed.\n",
        "GEN_MODEL = \"google/flan-t5-small\"  # compact; swap to flan-t5-base for better output\n",
        "gen_pipeline = pipeline(\"text2text-generation\", model=GEN_MODEL, device=-1)  # CPU default; in Colab you can set device=0 for GPU\n",
        "\n",
        "def generate_suggestions(jd_text: str, resume_text: str, missing_skills: List[str], top_k:int=5) -> str:\n",
        "    prompt = (\n",
        "        \"You are an expert career coach. Given the job description and a candidate resume, produce:\\n\"\n",
        "        \"1) A concise Relevance summary (1-2 lines),\\n\"\n",
        "        \"2) Top missing skills/certifications (bullet list),\\n\"\n",
        "        \"3) Practical improvement actions the candidate can do in 30 / 90 days (bulleted),\\n\\n\"\n",
        "        \"Job description:\\n\" + jd_text + \"\\n\\n\"\n",
        "        \"Candidate resume (short):\\n\" + (resume_text[:3000] if len(resume_text)>3000 else resume_text) + \"\\n\\n\"\n",
        "        \"Missing skills (from hard match): \" + (\", \".join(missing_skills) if missing_skills else \"None\") + \"\\n\\n\"\n",
        "        \"Produce a compact, actionable output.\"\n",
        "    )\n",
        "    out = gen_pipeline(prompt, max_length=1000, do_sample=False)\n",
        "    return out[0]['generated_text']\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb1D1Hj8J6vw",
        "outputId": "647c1061-5b1e-4350-cc75-ee52e2b001f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 12) Full pipeline function\n",
        "def evaluate_resume_against_jd(resume_path: str, jd_path: str, verbose: bool=True) -> Dict:\n",
        "    # read files\n",
        "    resume_text = normalize_text(extract_text(resume_path))\n",
        "    jd_text = normalize_text(extract_text(jd_path))\n",
        "    # parse JD\n",
        "    jd_parsed = parse_jd(jd_text)\n",
        "    required = jd_parsed.get('required', [])\n",
        "    nice = jd_parsed.get('nice_to_have', [])\n",
        "    # hard match\n",
        "    hard_score, missing_required, matched_scores = hard_match_score(required, resume_text)\n",
        "    # semantic match\n",
        "    sem_score = semantic_score(jd_text, resume_text)\n",
        "    # final score\n",
        "    final = compute_final_score(hard_score, sem_score)\n",
        "    verdict = verdict_from_score(final)\n",
        "    # suggestions using LLM (short)\n",
        "    suggestions = generate_suggestions(jd_text, resume_text, missing_required)\n",
        "    result = {\n",
        "        \"resume_path\": resume_path,\n",
        "        \"jd_path\": jd_path,\n",
        "        \"jd_parsed\": jd_parsed,\n",
        "        \"hard_score\": hard_score,\n",
        "        \"semantic_score\": sem_score,\n",
        "        \"final_score\": final,\n",
        "        \"verdict\": verdict,\n",
        "        \"missing_required\": missing_required,\n",
        "        \"matched_scores\": matched_scores,\n",
        "        \"suggestions\": suggestions\n",
        "    }\n",
        "    if verbose:\n",
        "        print(\"Hard score: \", hard_score)\n",
        "        print(\"Semantic score: \", sem_score)\n",
        "        print(\"Final score: \", final, \" Verdict:\", verdict)\n",
        "        print(\"Missing required items:\", missing_required)\n",
        "    return result"
      ],
      "metadata": {
        "id": "4mnaJHYaKCxE"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Upload Resume file\n",
        "print(\"ðŸ“„ Please upload the resume file (PDF/DOCX/TXT):\")\n",
        "resume_upload = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "8nVXTelNKJBQ",
        "outputId": "0e994efa-422f-403f-9262-7818098301b9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ Please upload the resume file (PDF/DOCX/TXT):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22311693-aa6d-462c-a54f-d319a6ae5d39\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22311693-aa6d-462c-a54f-d319a6ae5d39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Sreeram Venkata Phani Kiranmai Resume.docx to Sreeram Venkata Phani Kiranmai Resume (1).docx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload JD file\n",
        "print(\"ðŸ“„ Please upload the Job Description file (PDF/DOCX/TXT):\")\n",
        "jd_upload = files.upload()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "Lrw88N6-Ki-N",
        "outputId": "0d9d8c5e-02d4-4608-ba1c-64dcfc16cdc7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“„ Please upload the Job Description file (PDF/DOCX/TXT):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d40f2645-b391-4092-a24e-2ca86d356cd6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d40f2645-b391-4092-a24e-2ca86d356cd6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_jd_2 (1).pdf to sample_jd_2 (1) (4).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get file names (first uploaded in each step)\n",
        "resume_path = list(resume_upload.keys())[0]\n",
        "jd_path = list(jd_upload.keys())[0]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dJecjzE7Kukl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the evaluation\n",
        "result = evaluate_resume_against_jd(resume_path, jd_path)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBd_-yDZKyHV",
        "outputId": "6231018e-25c4-4a13-9d9c-8e445338a282"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=1000) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard score:  62.5\n",
            "Semantic score:  35.04\n",
            "Final score:  51.52  Verdict: Medium\n",
            "Missing required items: ['c', 'nlp', 'spark']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display structured result\n",
        "import pprint\n",
        "pprint.pprint(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0YYZAoNELMUo",
        "outputId": "62609e46-f91a-4b83-c799-903edf7cdb5b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'final_score': 51.52,\n",
            " 'hard_score': 62.5,\n",
            " 'jd_parsed': {'nice_to_have': [],\n",
            "               'required': ['c',\n",
            "                            'computer vision',\n",
            "                            'nlp',\n",
            "                            'numpy',\n",
            "                            'pandas',\n",
            "                            'python',\n",
            "                            'spark',\n",
            "                            'sql'],\n",
            "               'skills': ['c',\n",
            "                          'computer vision',\n",
            "                          'nlp',\n",
            "                          'numpy',\n",
            "                          'pandas',\n",
            "                          'python',\n",
            "                          'spark',\n",
            "                          'sql']},\n",
            " 'jd_path': 'sample_jd_2 (1) (4).pdf',\n",
            " 'matched_scores': [('computer vision', 100.0),\n",
            "                    ('numpy', 100.0),\n",
            "                    ('pandas', 100.0),\n",
            "                    ('python', 100.0),\n",
            "                    ('sql', 100.0)],\n",
            " 'missing_required': ['c', 'nlp', 'spark'],\n",
            " 'resume_path': 'Sreeram Venkata Phani Kiranmai Resume (1).docx',\n",
            " 'semantic_score': 35.04,\n",
            " 'suggestions': 'Top missing skills/certifications (bullet list), and '\n",
            "                'practical improvement actions the candidate can do in 30 / 90 '\n",
            "                'days (bulleted), Job description: Detailed Job Descriptions '\n",
            "                'for Walk-In Drive 1. Data Science Interns â€¢ Internship '\n",
            "                'Duration: 6 months, followed by permanent employment based on '\n",
            "                'performance â€¢ Bond: 2.6 years, including the internship '\n",
            "                'period (total 30 months from joining) â€¢ Role Overview: â€¢ Work '\n",
            "                'on data engineering, data visualization, and data science '\n",
            "                'tasks. â€¢ Build deep learning models using Generative AI, '\n",
            "                'Computer Vision, and NLP. â€¢ Apply ML and deep learning '\n",
            "                'algorithms effectively. â€¢ Work with data visualization tools '\n",
            "                'like Tableau or Power BI. â€¢ Perform data processing using '\n",
            "                'Pandas and Spark. â€¢ Possess strong analytical and '\n",
            "                'problem-solving skills. â€¢ Eligibility Criteria: â€¢ '\n",
            "                'Qualification: B.Tech, BE â€¢ Batch Eligibility: 2023 and '\n",
            "                'earlier pass-outs â€¢ Job Types: Full-time, Internship, '\n",
            "                'Fresher, Permanent â€¢ Stipend: 5,000 per month â€¢ Schedule: Day '\n",
            "                'shift, Monday to Friday â€¢ Location: Pune (Onsite) â€¢ Data '\n",
            "                'Engineer â€¢ Location: Pune (Onsite) â€¢',\n",
            " 'verdict': 'Medium'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, HTML\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def display_results(result):\n",
        "    # Title\n",
        "    display(HTML(\"<h2 style='color:#2E86C1'>ðŸ“Š Resume Relevance Evaluation Result</h2>\"))\n",
        "\n",
        "    # Gauge Chart for Final Score\n",
        "    fig, ax = plt.subplots(figsize=(5, 1.2))\n",
        "    ax.barh(0, result['final_score'], color=\"green\" if result['verdict']==\"High\" else \"orange\" if result['verdict']==\"Medium\" else \"red\")\n",
        "    ax.set_xlim(0, 100)\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(f\"Final Score: {result['final_score']}%\", fontsize=12, pad=10)\n",
        "    plt.show()\n",
        "\n",
        "    # Verdict Box\n",
        "    verdict_color = \"green\" if result['verdict']==\"High\" else \"orange\" if result['verdict']==\"Medium\" else \"red\"\n",
        "    verdict_html = f\"\"\"\n",
        "    <div style=\"border:2px solid {verdict_color}; padding:15px; border-radius:10px; background:#F8F9F9;\">\n",
        "        <h3>Final Verdict: <span style=\"color:{verdict_color};\">{result['verdict']}</span></h3>\n",
        "        <p><b>Hard Match Score:</b> {result['hard_score']}%</p>\n",
        "        <p><b>Semantic Similarity:</b> {result['semantic_score']}%</p>\n",
        "    </div>\n",
        "    \"\"\"\n",
        "    display(HTML(verdict_html))\n",
        "\n",
        "    # Missing skills\n",
        "    if result['missing_required']:\n",
        "        missing_df = pd.DataFrame(result['missing_required'], columns=[\"ðŸš¨ Missing Required Skills\"])\n",
        "        display(missing_df.style.set_properties(**{'background-color': '#FADBD8'}))\n",
        "    else:\n",
        "        display(HTML(\"<p style='color:green; font-weight:bold;'>âœ… No required skills missing!</p>\"))\n",
        "\n",
        "    # Suggestions\n",
        "    display(HTML(\"<h3 style='color:#117A65'>ðŸ’¡ Suggested Improvements</h3>\"))\n",
        "    display(HTML(f\"<div style='white-space:pre-wrap; background:#EBF5FB; padding:10px; border-radius:10px;'>{result['suggestions']}</div>\"))\n"
      ],
      "metadata": {
        "id": "NrcTWrssLi13"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6effad7b",
        "outputId": "2c5e0a50-a081-4367-bac3-4fa48d2193e6"
      },
      "source": [
        "%%writefile evaluate.py\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import docx2txt\n",
        "from rapidfuzz import fuzz, process\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "# 3) Utilities: text extraction\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    texts = []\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            txt = page.extract_text()\n",
        "            if txt:\n",
        "                texts.append(txt)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def extract_text_from_docx(path: str) -> str:\n",
        "    return docx2txt.process(path)\n",
        "\n",
        "def extract_text(path: str) -> str:\n",
        "    ext = path.lower().split('.')[-1]\n",
        "    if ext == 'pdf':\n",
        "        return extract_text_from_pdf(path)\n",
        "    elif ext in ('docx', 'doc'):\n",
        "        return extract_text_from_docx(path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type: \" + ext)\n",
        "\n",
        "# 4) Preprocessing\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = re.sub(r'\\r\\n', '\\n', text)\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# 5) Lightweight section extraction heuristics (Skills / Education / Projects)\n",
        "SECTION_HEADINGS = [\n",
        "    r'\\bskills\\b', r'\\btechnical skills\\b', r'\\bprogramming skills\\b',\n",
        "    r'\\beducation\\b', r'\\bprojects\\b', r'\\bexperience\\b', r'\\bcertifications\\b'\n",
        "]\n",
        "\n",
        "def find_sections(text: str) -> Dict[str,str]:\n",
        "    # Very simple heuristic: split by common headings\n",
        "    # returns dict of heading -> content\n",
        "    lower = text.lower()\n",
        "    # find indices of headings\n",
        "    headings_pos = []\n",
        "    for h in SECTION_HEADINGS:\n",
        "        for m in re.finditer(h, lower):\n",
        "            headings_pos.append((m.start(), m.group()))\n",
        "    headings_pos.sort()\n",
        "    sections = {}\n",
        "    if not headings_pos:\n",
        "        sections['full'] = text\n",
        "        return sections\n",
        "    # boundaries\n",
        "    for i, (pos, head) in enumerate(headings_pos):\n",
        "        start = pos\n",
        "        end = headings_pos[i+1][0] if i+1 < len(headings_pos) else len(text)\n",
        "        name = re.sub(r'[^a-z ]','', head).strip()\n",
        "        content = text[start:end]\n",
        "        sections[name] = content\n",
        "    # add full text\n",
        "    sections['full'] = text\n",
        "    return sections\n",
        "\n",
        "# 6) Skill extraction by matching against a skill-list (can be extended)\n",
        "# We'll provide a default skill list; in production load from curated DB.\n",
        "DEFAULT_SKILLS = [\n",
        "    \"python\",\"java\",\"c++\",\"c\",\"c#\",\"sql\",\"nosql\",\"mongodb\",\"postgresql\",\"mysql\",\n",
        "    \"tensorflow\",\"pytorch\",\"keras\",\"scikit-learn\",\"transformers\",\"nlp\",\"computer vision\",\n",
        "    \"cv\",\"docker\",\"kubernetes\",\"aws\",\"azure\",\"gcp\",\"rest api\",\"fastapi\",\"flask\",\n",
        "    \"git\",\"linux\",\"spark\",\"hadoop\",\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\n",
        "    \"react\",\"nodejs\",\"javascript\",\"html\",\"css\",\"bash\",\"shell\",\"opencv\"\n",
        "]\n",
        "\n",
        "def extract_skills_from_text(text: str, skill_list: List[str]=None) -> List[str]:\n",
        "    if skill_list is None:\n",
        "        skill_list = DEFAULT_SKILLS\n",
        "    found = set()\n",
        "    lower = text.lower() # Ensure this is 'lower'\n",
        "    for skill in skill_list:\n",
        "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', lower): # Use 'lower' here\n",
        "            found.add(skill)\n",
        "    # also capture candidate-defined ones using fuzzy token matching\n",
        "    tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', text)\n",
        "    for tok in set(tokens):\n",
        "        # Use try-except to handle potential issues with extractOne returning more than 2 values\n",
        "        try:\n",
        "            # Ensure 'lower' is used in the fuzzy matching context if needed, but here it's tok.lower() vs skill_list\n",
        "            match, score = process.extractOne(tok.lower(), skill_list, scorer=fuzz.partial_ratio)\n",
        "            if score and score >= 90:\n",
        "                found.add(match)\n",
        "        except ValueError:\n",
        "            # If extractOne returns more than 2 values, skip this token or handle as needed\n",
        "            continue\n",
        "    return sorted(found)\n",
        "\n",
        "# 7) JD parsing: heuristics to pull required and nice-to-have\n",
        "def parse_jd(jd_text: str) -> Dict[str, List[str]]:\n",
        "    jd_lower = jd_text.lower()\n",
        "    # Try to find \"must have / required\" lists\n",
        "    required = []\n",
        "    nice = []\n",
        "    # Common patterns\n",
        "    required_patterns = [r'(must have|must|required|requirements:|required skills:|responsibilities:)',]\n",
        "    nice_patterns = [r'(nice to have|good to have|preferred|preferred qualifications)',]\n",
        "    # split lines and attempt to classify lines\n",
        "    lines = [l.strip() for l in jd_text.splitlines() if l.strip()]\n",
        "    cur_bucket = None\n",
        "    for line in lines:\n",
        "        ll = line.lower()\n",
        "        if any(p in ll for p in required_patterns):\n",
        "            cur_bucket = 'required'\n",
        "            continue\n",
        "        if any(p in ll for p in nice_patterns):\n",
        "            cur_bucket = 'nice'\n",
        "            continue\n",
        "        # bullets or comma-separated\n",
        "        if line.startswith('-') or line.startswith('*') or len(line.split())<12:\n",
        "            bucket = cur_bucket if cur_bucket else 'required'  # default assume required\n",
        "            if bucket == 'required':\n",
        "                required.append(line.strip('-* ').strip())\n",
        "            else:\n",
        "                nice.append(line.strip('-* ').strip())\n",
        "        else:\n",
        "            # longer sentences, also try to extract skills using our skill list\n",
        "            # fallback: gather any skill words\n",
        "            pass\n",
        "    # additionally, extract skills from whole JD text\n",
        "    jd_skills = extract_skills_from_text(jd_text)\n",
        "    # if we couldn't parse bullets, use jd_skills as required\n",
        "    if not required and jd_skills:\n",
        "        required = jd_skills\n",
        "    # rudimentary cleaning (split comma lists)\n",
        "    def split_items(items):\n",
        "        out=[]\n",
        "        for it in items:\n",
        "            for part in re.split(r'[;,/]| or |\\band\\b', it):\n",
        "                p = part.strip()\n",
        "                if p:\n",
        "                    out.append(p)\n",
        "        return list(dict.fromkeys(out))\n",
        "    required = split_items(required)\n",
        "    nice = split_items(nice)\n",
        "    return {\"required\": required, \"nice_to_have\": nice, \"skills\": jd_skills}\n",
        "\n",
        "# 8) Embeddings setup (SentenceTransformers)\n",
        "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    return embed_model.encode(text, convert_to_tensor=True)\n",
        "\n",
        "# 9) Matching & scoring\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_sim_vec(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    if np.all(a==0) or np.all(b==0):\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
        "\n",
        "def hard_match_score(jd_required: List[str], resume_text: str) -> Tuple[float, List[str], List[Tuple[str,float]]]:\n",
        "    \"\"\"\n",
        "    Returns: score between 0-100, list of missing required items, list of (matched_item, score)\n",
        "    We use fuzzy matching for resilience.\n",
        "    \"\"\"\n",
        "    resume_lower = resume_text.lower() # This variable name is correct here\n",
        "    matched = []\n",
        "    missing = []\n",
        "    matched_scores = []\n",
        "    for req in jd_required:\n",
        "        req_clean = req.strip().lower()\n",
        "        # exact word presence?\n",
        "        if re.search(r'\\b' + re.escape(req_clean) + r'\\b', resume_lower):\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, 100.0))\n",
        "            continue\n",
        "        # fuzzy search for tokens\n",
        "        tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', req_clean)\n",
        "        # take highest fuzzy match across resume text tokens\n",
        "        score = 0\n",
        "        for tok in tokens:\n",
        "            s = fuzz.partial_ratio(tok, resume_lower) # This uses resume_lower, which is correct in THIS function\n",
        "            if s>score:\n",
        "                score = s\n",
        "        if score >= 75:\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, float(score)))\n",
        "        else:\n",
        "            missing.append(req)\n",
        "    # Score = matched_count / total_required * 100, weighted by fuzzy score\n",
        "    if not jd_required:\n",
        "        return 0.0, [], []\n",
        "    weighted = 0.0\n",
        "    for m, sc in matched_scores:\n",
        "        weighted += sc/100.0\n",
        "    hard_score = (weighted / len(jd_required)) * 100.0\n",
        "    return round(hard_score,2), missing, matched_scores\n",
        "\n",
        "def semantic_score(jd_text: str, resume_text: str) -> float:\n",
        "    # embed full jd and resume\n",
        "    e_jd = embed_model.encode(jd_text, convert_to_tensor=True)\n",
        "    e_res = embed_model.encode(resume_text, convert_to_tensor=True)\n",
        "    sim = util.pytorch_cos_sim(e_jd, e_res).item()\n",
        "    return round(sim * 100.0, 2)  # convert 0-1 -> 0-100\n",
        "\n",
        "# 10) Weighted scoring formula and verdict\n",
        "def compute_final_score(hard: float, semantic: float, weights: Dict[str,float]=None):\n",
        "    # default weights: hard 0.6, semantic 0.4\n",
        "    if weights is None:\n",
        "        weights = {\"hard\": 0.6, \"semantic\": 0.4}\n",
        "    final = hard*weights['hard'] + semantic*weights['semantic']\n",
        "    return round(final, 2)\n",
        "\n",
        "def verdict_from_score(score: float):\n",
        "    if score >= 75:\n",
        "        return \"High\"\n",
        "    elif score >= 50:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\"\n",
        "\n",
        "# 11) LLM-based improvement suggestion (uses HF pipeline; small model by default)\n",
        "# Note: you can swap model name to a larger LLM if needed.\n",
        "GEN_MODEL = \"google/flan-t5-small\"  # compact; swap to flan-t5-base for better output\n",
        "gen_pipeline = pipeline(\"text2text-generation\", model=GEN_MODEL)\n",
        "\n",
        "def generate_suggestions(jd_text: str, resume_text: str, missing_skills: List[str]) -> str:\n",
        "    prompt = (\n",
        "        \"You are an expert career coach. Given the job description and a candidate resume, produce:\\n\"\n",
        "        \"1) A concise Relevance summary (1-2 lines),\\n\"\n",
        "        \"2) Top missing skills/certifications (bullet list),\\n\"\n",
        "        \"3) Practical improvement actions the candidate can do in 30 / 90 days (bulleted),\\n\\n\"\n",
        "        \"Job description:\\n\" + jd_text + \"\\n\\n\"\n",
        "        \"Candidate resume (short):\\n\" + (resume_text[:3000] if len(resume_text)>3000 else resume_text) + \"\\n\\n\"\n",
        "        \"Missing skills (from hard match): \" + (\", \".join(missing_skills) if missing_skills else \"None\") + \"\\n\\n\"\n",
        "        \"Produce a compact, actionable output.\"\n",
        "    )\n",
        "    out = gen_pipeline(prompt, max_length=400, do_sample=False)\n",
        "    return out[0]['generated_text']\n",
        "\n",
        "# 12) Full pipeline function\n",
        "def evaluate_resume_against_jd(resume_path: str, jd_path: str, verbose: bool=True) -> Dict:\n",
        "    # read files\n",
        "    resume_text = normalize_text(extract_text(resume_path))\n",
        "    jd_text = normalize_text(extract_text(jd_path))\n",
        "    # parse JD\n",
        "    jd_parsed = parse_jd(jd_text)\n",
        "    required = jd_parsed.get('required', [])\n",
        "    nice = jd_parsed.get('nice_to_have', [])\n",
        "    # hard match\n",
        "    hard_score, missing_required, matched_scores = hard_match_score(required, resume_text)\n",
        "    # semantic match\n",
        "    sem_score = semantic_score(jd_text, resume_text)\n",
        "    # final score\n",
        "    final = compute_final_score(hard_score, sem_score)\n",
        "    verdict = verdict_from_score(final)\n",
        "    # suggestions using LLM (short)\n",
        "    suggestions = generate_suggestions(jd_text, resume_text, missing_required)\n",
        "    result = {\n",
        "        \"resume_path\": resume_path,\n",
        "        \"jd_path\": jd_path,\n",
        "        \"jd_parsed\": jd_parsed,\n",
        "        \"hard_score\": hard_score,\n",
        "        \"semantic_score\": sem_score,\n",
        "        \"final_score\": final,\n",
        "        \"verdict\": verdict,\n",
        "        \"missing_required\": missing_required,\n",
        "        \"matched_scores\": matched_scores,\n",
        "        \"suggestions\": suggestions\n",
        "    }\n",
        "    if verbose:\n",
        "        print(\"Hard score: \", hard_score)\n",
        "        print(\"Semantic score: \", sem_score)\n",
        "        print(\"Final score: \", final, \" Verdict:\", verdict)\n",
        "        print(\"Missing required items:\", missing_required)\n",
        "    return result"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting evaluate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "# Save this as app.py and run: streamlit run app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Include the content of evaluate.py here\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import math\n",
        "from typing import List, Dict, Tuple\n",
        "import numpy as np\n",
        "import pdfplumber\n",
        "import docx2txt\n",
        "from rapidfuzz import fuzz, process\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "from transformers import pipeline\n",
        "\n",
        "# 3) Utilities: text extraction\n",
        "def extract_text_from_pdf(path: str) -> str:\n",
        "    texts = []\n",
        "    with pdfplumber.open(path) as pdf:\n",
        "        for page in pdf.pages:\n",
        "            txt = page.extract_text()\n",
        "            if txt:\n",
        "                texts.append(txt)\n",
        "    return \"\\n\".join(texts)\n",
        "\n",
        "def extract_text_from_docx(path: str) -> str:\n",
        "    return docx2txt.process(path)\n",
        "\n",
        "def extract_text(path: str) -> str:\n",
        "    ext = path.lower().split('.')[-1]\n",
        "    if ext == 'pdf':\n",
        "        return extract_text_from_pdf(path)\n",
        "    elif ext in ('docx', 'doc'):\n",
        "        return extract_text_from_docx(path)\n",
        "    else:\n",
        "        raise ValueError(\"Unsupported file type: \" + ext)\n",
        "\n",
        "# 4) Preprocessing\n",
        "def normalize_text(text: str) -> str:\n",
        "    text = re.sub(r'\\r\\n', '\\n', text)\n",
        "    text = re.sub(r'\\n{2,}', '\\n', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    return text.strip()\n",
        "\n",
        "# 5) Lightweight section extraction heuristics (Skills / Education / Projects)\n",
        "SECTION_HEADINGS = [\n",
        "    r'\\bskills\\b', r'\\btechnical skills\\b', r'\\bprogramming skills\\b',\n",
        "    r'\\beducation\\b', r'\\bprojects\\b', r'\\bexperience\\b', r'\\bcertifications\\b'\n",
        "]\n",
        "\n",
        "def find_sections(text: str) -> Dict[str,str]:\n",
        "    # Very simple heuristic: split by common headings\n",
        "    # returns dict of heading -> content\n",
        "    lower = text.lower()\n",
        "    # find indices of headings\n",
        "    headings_pos = []\n",
        "    for h in SECTION_HEADINGS:\n",
        "        for m in re.finditer(h, lower):\n",
        "            headings_pos.append((m.start(), m.group()))\n",
        "    headings_pos.sort()\n",
        "    sections = {}\n",
        "    if not headings_pos:\n",
        "        sections['full'] = text\n",
        "        return sections\n",
        "    # boundaries\n",
        "    for i, (pos, head) in enumerate(headings_pos):\n",
        "        start = pos\n",
        "        end = headings_pos[i+1][0] if i+1 < len(headings_pos) else len(text)\n",
        "        name = re.sub(r'[^a-z ]','', head).strip()\n",
        "        content = text[start:end]\n",
        "        sections[name] = content\n",
        "    # add full text\n",
        "    sections['full'] = text\n",
        "    return sections\n",
        "\n",
        "# 6) Skill extraction by matching against a skill-list (can be extended)\n",
        "# We'll provide a default skill list; in production load from curated DB.\n",
        "DEFAULT_SKILLS = [\n",
        "    \"python\",\"java\",\"c++\",\"c\",\"c#\",\"sql\",\"nosql\",\"mongodb\",\"postgresql\",\"mysql\",\n",
        "    \"tensorflow\",\"pytorch\",\"keras\",\"scikit-learn\",\"transformers\",\"nlp\",\"computer vision\",\n",
        "    \"cv\",\"docker\",\"kubernetes\",\"aws\",\"azure\",\"gcp\",\"rest api\",\"fastapi\",\"flask\",\n",
        "    \"git\",\"linux\",\"spark\",\"hadoop\",\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\n",
        "    \"react\",\"nodejs\",\"javascript\",\"html\",\"css\",\"bash\",\"shell\",\"opencv\"\n",
        "]\n",
        "\n",
        "def extract_skills_from_text(text: str, skill_list: List[str]=None) -> List[str]:\n",
        "    if skill_list is None:\n",
        "        skill_list = DEFAULT_SKILLS\n",
        "    found = set()\n",
        "    lower = text.lower() # Ensure this is 'lower'\n",
        "    for skill in skill_list:\n",
        "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', lower): # Use 'lower' here\n",
        "            found.add(skill)\n",
        "    # also capture candidate-defined ones using fuzzy token matching\n",
        "    tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', text)\n",
        "    for tok in set(tokens):\n",
        "        # Use try-except to handle potential issues with extractOne returning more than 2 values\n",
        "        try:\n",
        "            # Ensure 'lower' is used in the fuzzy matching context if needed, but here it's tok.lower() vs skill_list\n",
        "            match, score = process.extractOne(tok.lower(), skill_list, scorer=fuzz.partial_ratio)\n",
        "            if score and score >= 90:\n",
        "                found.add(match)\n",
        "        except ValueError:\n",
        "            # If extractOne returns more than 2 values, skip this token or handle as needed\n",
        "            continue\n",
        "    return sorted(found)\n",
        "\n",
        "# 7) JD parsing: heuristics to pull required and nice-to-have\n",
        "def parse_jd(jd_text: str) -> Dict[str, List[str]]:\n",
        "    jd_lower = jd_text.lower()\n",
        "    # Try to find \"must have / required\" lists\n",
        "    required = []\n",
        "    nice = []\n",
        "    # Common patterns\n",
        "    required_patterns = [r'(must have|must|required|requirements:|required skills:|responsibilities:)',]\n",
        "    nice_patterns = [r'(nice to have|good to have|preferred|preferred qualifications)',]\n",
        "    # split lines and attempt to classify lines\n",
        "    lines = [l.strip() for l in jd_text.splitlines() if l.strip()]\n",
        "    cur_bucket = None\n",
        "    for line in lines:\n",
        "        ll = line.lower()\n",
        "        if any(p in ll for p in required_patterns):\n",
        "            cur_bucket = 'required'\n",
        "            continue\n",
        "        if any(p in ll for p in nice_patterns):\n",
        "            cur_bucket = 'nice'\n",
        "            continue\n",
        "        # bullets or comma-separated\n",
        "        if line.startswith('-') or line.startswith('*') or len(line.split())<12:\n",
        "            bucket = cur_bucket if cur_bucket else 'required'  # default assume required\n",
        "            if bucket == 'required':\n",
        "                required.append(line.strip('-* ').strip())\n",
        "            else:\n",
        "                nice.append(line.strip('-* ').strip())\n",
        "        else:\n",
        "            # longer sentences, also try to extract skills using our skill list\n",
        "            # fallback: gather any skill words\n",
        "            pass\n",
        "    # additionally, extract skills from whole JD text\n",
        "    jd_skills = extract_skills_from_text(jd_text)\n",
        "    # if we couldn't parse bullets, use jd_skills as required\n",
        "    if not required and jd_skills:\n",
        "        required = jd_skills\n",
        "    # rudimentary cleaning (split comma lists)\n",
        "    def split_items(items):\n",
        "        out=[]\n",
        "        for it in items:\n",
        "            for part in re.split(r'[;,/]| or |\\band\\b', it):\n",
        "                p = part.strip()\n",
        "                if p:\n",
        "                    out.append(p)\n",
        "        return list(dict.fromkeys(out))\n",
        "    required = split_items(required)\n",
        "    nice = split_items(nice)\n",
        "    return {\"required\": required, \"nice_to_have\": nice, \"skills\": jd_skills}\n",
        "\n",
        "# 8) Embeddings setup (SentenceTransformers)\n",
        "EMBED_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "embed_model = SentenceTransformer(EMBED_MODEL_NAME)\n",
        "\n",
        "def get_embedding(text: str):\n",
        "    return embed_model.encode(text, convert_to_tensor=True)\n",
        "\n",
        "# 9) Matching & scoring\n",
        "from numpy.linalg import norm\n",
        "\n",
        "def cosine_sim_vec(a, b):\n",
        "    a = np.array(a)\n",
        "    b = np.array(b)\n",
        "    if np.all(a==0) or np.all(b==0):\n",
        "        return 0.0\n",
        "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))\n",
        "\n",
        "def hard_match_score(jd_required: List[str], resume_text: str) -> Tuple[float, List[str], List[Tuple[str,float]]]:\n",
        "    \"\"\"\n",
        "    Returns: score between 0-100, list of missing required items, list of (matched_item, score)\n",
        "    We use fuzzy matching for resilience.\n",
        "    \"\"\"\n",
        "    resume_lower = resume_text.lower() # This variable name is correct here\n",
        "    matched = []\n",
        "    missing = []\n",
        "    matched_scores = []\n",
        "    for req in jd_required:\n",
        "        req_clean = req.strip().lower()\n",
        "        # exact word presence?\n",
        "        if re.search(r'\\b' + re.escape(req_clean) + r'\\b', resume_lower):\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, 100.0))\n",
        "            continue\n",
        "        # fuzzy search for tokens\n",
        "        tokens = re.findall(r'[A-Za-z\\+#\\.\\-]{2,}', req_clean)\n",
        "        # take highest fuzzy match across resume text tokens\n",
        "        score = 0\n",
        "        for tok in tokens:\n",
        "            s = fuzz.partial_ratio(tok, resume_lower) # This uses resume_lower, which is correct in THIS function\n",
        "            if s>score:\n",
        "                score = s\n",
        "        if score >= 75:\n",
        "            matched.append(req)\n",
        "            matched_scores.append((req, float(score)))\n",
        "        else:\n",
        "            missing.append(req)\n",
        "    # Score = matched_count / total_required * 100, weighted by fuzzy score\n",
        "    if not jd_required:\n",
        "        return 0.0, [], []\n",
        "    weighted = 0.0\n",
        "    for m, sc in matched_scores:\n",
        "        weighted += sc/100.0\n",
        "    hard_score = (weighted / len(jd_required)) * 100.0\n",
        "    return round(hard_score,2), missing, matched_scores\n",
        "\n",
        "def semantic_score(jd_text: str, resume_text: str) -> float:\n",
        "    # embed full jd and resume\n",
        "    e_jd = embed_model.encode(jd_text, convert_to_tensor=True)\n",
        "    e_res = embed_model.encode(resume_text, convert_to_tensor=True)\n",
        "    sim = util.pytorch_cos_sim(e_jd, e_res).item()\n",
        "    return round(sim * 100.0, 2)  # convert 0-1 -> 0-100\n",
        "\n",
        "# 10) Weighted scoring formula and verdict\n",
        "def compute_final_score(hard: float, semantic: float, weights: Dict[str,float]=None):\n",
        "    # default weights: hard 0.6, semantic 0.4\n",
        "    if weights is None:\n",
        "        weights = {\"hard\": 0.6, \"semantic\": 0.4}\n",
        "    final = hard*weights['hard'] + semantic*weights['semantic']\n",
        "    return round(final, 2)\n",
        "\n",
        "def verdict_from_score(score: float):\n",
        "    if score >= 75:\n",
        "        return \"High\"\n",
        "    elif score >= 50:\n",
        "        return \"Medium\"\n",
        "    else:\n",
        "        return \"Low\"\n",
        "\n",
        "# 11) LLM-based improvement suggestion (uses HF pipeline; small model by default)\n",
        "# Note: you can swap model name to a larger LLM if needed.\n",
        "GEN_MODEL = \"google/flan-t5-small\"  # compact; swap to flan-t5-base for better output\n",
        "gen_pipeline = pipeline(\"text2text-generation\", model=GEN_MODEL)\n",
        "\n",
        "def generate_suggestions(jd_text: str, resume_text: str, missing_skills: List[str]) -> str:\n",
        "    prompt = (\n",
        "        \"You are an expert career coach. Given the job description and a candidate resume, produce:\\n\"\n",
        "        \"1) A concise Relevance summary (1-2 lines),\\n\"\n",
        "        \"2) Top missing skills/certifications (bullet list),\\n\"\n",
        "        \"3) Practical improvement actions the candidate can do in 30 / 90 days (bulleted),\\n\\n\"\n",
        "        \"Job description:\\n\" + jd_text + \"\\n\\n\"\n",
        "        \"Candidate resume (short):\\n\" + (resume_text[:3000] if len(resume_text)>3000 else resume_text) + \"\\n\\n\"\n",
        "        \"Missing skills (from hard match): \" + (\", \".join(missing_skills) if missing_skills else \"None\") + \"\\n\\n\"\n",
        "        \"Produce a compact, actionable output.\"\n",
        "    )\n",
        "    out = gen_pipeline(prompt, max_length=400, do_sample=False)\n",
        "    return out[0]['generated_text']\n",
        "\n",
        "# 12) Full pipeline function (adapted for Streamlit)\n",
        "def evaluate_resume_against_jd(resume_path: str, jd_path: str, verbose: bool=True) -> Dict:\n",
        "    # read files\n",
        "    resume_text = normalize_text(extract_text(resume_path))\n",
        "    jd_text = normalize_text(extract_text(jd_path))\n",
        "    # parse JD\n",
        "    jd_parsed = parse_jd(jd_text)\n",
        "    required = jd_parsed.get('required', [])\n",
        "    nice = jd_parsed.get('nice_to_have', [])\n",
        "    # hard match\n",
        "    hard_score, missing_required, matched_scores = hard_match_score(required, resume_text)\n",
        "    # semantic match\n",
        "    sem_score = semantic_score(jd_text, resume_text)\n",
        "    # final score\n",
        "    final = compute_final_score(hard_score, sem_score)\n",
        "    verdict = verdict_from_score(final)\n",
        "    # suggestions using LLM (short)\n",
        "    suggestions = generate_suggestions(jd_text, resume_text, missing_required)\n",
        "    result = {\n",
        "        \"resume_path\": resume_path,\n",
        "        \"jd_path\": jd_path,\n",
        "        \"jd_parsed\": jd_parsed,\n",
        "        \"hard_score\": hard_score,\n",
        "        \"semantic_score\": sem_score,\n",
        "        \"final_score\": final,\n",
        "        \"verdict\": verdict,\n",
        "        \"missing_required\": missing_required,\n",
        "        \"matched_scores\": matched_scores,\n",
        "        \"suggestions\": suggestions\n",
        "    }\n",
        "    # In Streamlit app, we don't print verbose output here, Streamlit components handle display\n",
        "    return result\n",
        "\n",
        "\n",
        "st.set_page_config(page_title=\"Resume Relevance Checker\", layout=\"wide\")\n",
        "\n",
        "st.title(\"ðŸ“Š Automated Resume Relevance Check System\")\n",
        "\n",
        "# Upload files\n",
        "resume_file = st.file_uploader(\"ðŸ“„ Upload Resume (PDF/DOCX/TXT)\", type=[\"pdf\", \"docx\", \"txt\"])\n",
        "jd_file = st.file_uploader(\"ðŸ“„ Upload Job Description (PDF/DOCX/TXT)\", type=[\"pdf\", \"docx\", \"txt\"])\n",
        "\n",
        "if resume_file and jd_file:\n",
        "    # Save uploads temporarily\n",
        "    # Streamlit handles temporary files, we just need the path\n",
        "    # No need to explicitly save to a new temp file here, Streamlit provides a file-like object\n",
        "    # We need to get the file content and pass it or save it if extract_text requires a path\n",
        "\n",
        "    # A common pattern is to save the uploaded file to a temporary location\n",
        "    # and pass that path to your evaluation function.\n",
        "    import tempfile\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(resume_file.name)[1]) as tmp_resume_file:\n",
        "        tmp_resume_file.write(resume_file.getvalue())\n",
        "        resume_path = tmp_resume_file.name\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(jd_file.name)[1]) as tmp_jd_file:\n",
        "        tmp_jd_file.write(jd_file.getvalue())\n",
        "        jd_path = tmp_jd_file.name\n",
        "\n",
        "    try:\n",
        "        # Run evaluation\n",
        "        result = evaluate_resume_against_jd(resume_path, jd_path, verbose=False)\n",
        "\n",
        "        # Show scores\n",
        "        st.metric(\"Hard Match Score\", f\"{result['hard_score']}%\")\n",
        "        st.metric(\"Semantic Similarity\", f\"{result['semantic_score']}%\")\n",
        "        st.metric(\"Final Score\", f\"{result['final_score']}%\", delta=result['verdict'])\n",
        "\n",
        "        # Gauge chart\n",
        "        fig, ax = plt.subplots(figsize=(5,1.2))\n",
        "        ax.barh(0, result['final_score'], color=\"green\" if result['verdict']==\"High\" else \"orange\" if result['verdict']==\"Medium\" else \"red\")\n",
        "        ax.set_xlim(0, 100)\n",
        "        ax.set_yticks([])\n",
        "        ax.set_title(f\"Final Score: {result['final_score']}%\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # Missing skills\n",
        "        if result[\"missing_required\"]:\n",
        "            st.subheader(\"ðŸš¨ Missing Required Skills\")\n",
        "            st.table(pd.DataFrame(result[\"missing_required\"], columns=[\"Skill\"]))\n",
        "        else:\n",
        "            st.success(\"âœ… No required skills missing!\")\n",
        "\n",
        "        # Suggestions\n",
        "        st.subheader(\"ðŸ’¡ Suggested Improvements\")\n",
        "        st.info(result[\"suggestions\"])\n",
        "\n",
        "    finally:\n",
        "        # Clean up temporary files\n",
        "        os.remove(resume_path)\n",
        "        os.remove(jd_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfhsQo7-JrQs",
        "outputId": "76e5c43f-bfdd-4179-9677-dc0c418a9483"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import os\n",
        "import tempfile\n",
        "from evaluate import evaluate_resume_against_jd # Assuming evaluate.py is available\n",
        "\n",
        "# Create file upload widgets\n",
        "resume_file_upload = widgets.FileUpload(\n",
        "    accept='.pdf,.docx,.txt',\n",
        "    multiple=False,\n",
        "    description='Upload Resume',\n",
        "    button_style='primary',\n",
        "    tooltip='Upload your resume (PDF, DOCX, or TXT)',\n",
        "    icon='file'\n",
        ")\n",
        "\n",
        "jd_file_upload = widgets.FileUpload(\n",
        "    accept='.pdf,.docx,.txt',\n",
        "    multiple=False,\n",
        "    description='Upload Job Description',\n",
        "    button_style='primary',\n",
        "    tooltip='Upload the job description (PDF, DOCX, or TXT)',\n",
        "    icon='file'\n",
        ")\n",
        "\n",
        "# Create a button to trigger evaluation\n",
        "run_button = widgets.Button(\n",
        "    description=\"Evaluate Resume\",\n",
        "    disabled=False,\n",
        "    button_style='success', # 'success', 'info', 'warning', 'danger' or ''\n",
        "    tooltip='Click to evaluate',\n",
        "    icon='play'\n",
        ")\n",
        "\n",
        "# Create an output area\n",
        "output_area = widgets.Output()\n",
        "\n",
        "# Layout the widgets\n",
        "upload_box = widgets.VBox([\n",
        "    widgets.Label(\"Upload Files:\"),\n",
        "    resume_file_upload,\n",
        "    jd_file_upload\n",
        "])\n",
        "\n",
        "button_box = widgets.HBox([run_button])\n",
        "\n",
        "# Main container with padding and border\n",
        "main_layout = widgets.VBox([\n",
        "    widgets.HTML(\"<h2>âœ¨ Resume Relevance Checker</h2>\"),\n",
        "    upload_box,\n",
        "    button_box,\n",
        "    widgets.HTML(\"<h3>Results:</h3>\"),\n",
        "    output_area\n",
        "], layout=widgets.Layout(border='1px solid lightgray', padding='20px', margin='20px', width='auto'))\n",
        "\n",
        "\n",
        "# Define the button click event handler\n",
        "def on_button_click(b):\n",
        "    with output_area:\n",
        "        clear_output()  # Clear previous output\n",
        "\n",
        "        # More robust check if files have been uploaded\n",
        "        if not resume_file_upload.value or not jd_file_upload.value or not list(resume_file_upload.value.values()) or not list(jd_file_upload.value.values()):\n",
        "            print(\"Please upload both a resume and a job description file.\")\n",
        "            return\n",
        "\n",
        "        print(\"Processing files and evaluating...\")\n",
        "\n",
        "        # --- Debugging: Print the value of the upload widgets ---\n",
        "        # print(\"Resume file upload value:\", resume_file_upload.value)\n",
        "        # print(\"JD file upload value:\", jd_file_upload.value)\n",
        "        # -----------------------------------------------------\n",
        "\n",
        "        # Get the original filenames and content\n",
        "        resume_info = list(resume_file_upload.value.values())[0]\n",
        "        jd_info = list(jd_file_upload.value.values())[0]\n",
        "\n",
        "        # Access 'name' from the nested 'metadata' dictionary\n",
        "        resume_filename = resume_info['metadata']['name']\n",
        "        jd_filename = jd_info['metadata']['name']\n",
        "\n",
        "        # Save the uploaded files to temporary files with original extensions\n",
        "        try:\n",
        "            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(resume_filename)[1], delete=False) as tmp_resume:\n",
        "                tmp_resume.write(resume_info['content'])\n",
        "                resume_path = tmp_resume.name\n",
        "\n",
        "            with tempfile.NamedTemporaryFile(suffix=os.path.splitext(jd_filename)[1], delete=False) as tmp_jd:\n",
        "                tmp_jd.write(jd_info['content'])\n",
        "                jd_path = tmp_jd.name\n",
        "\n",
        "            # Call the evaluation function from evaluate.py\n",
        "            result = evaluate_resume_against_jd(resume_path, jd_path, verbose=False)\n",
        "\n",
        "            # Display the results in a formatted way using HTML for better styling\n",
        "            display(HTML(\"<h4>ðŸ“Š Evaluation Results</h4>\"))\n",
        "            display(HTML(f\"<p><b>Final Score:</b> {result['final_score']}% ({result['verdict']})</p>\"))\n",
        "            display(HTML(f\"<p><b>Hard Match Score:</b> {result['hard_score']}%</p>\"))\n",
        "            display(HTML(f\"<p><b>Semantic Similarity:</b> {result['semantic_score']}%</p>\"))\n",
        "\n",
        "            display(HTML(\"<h4>ðŸš¨ Missing Required Skills:</h4>\"))\n",
        "            if result['missing_required']:\n",
        "                missing_html = \"<ul>\" + \"\".join([f\"<li>{skill}</li>\" for skill in result['missing_required']]) + \"</ul>\"\n",
        "                display(HTML(missing_html))\n",
        "            else:\n",
        "                display(HTML(\"<p>âœ… No required skills missing!</p>\"))\n",
        "\n",
        "            display(HTML(\"<h4>ðŸ’¡ Suggested Improvements:</h4>\"))\n",
        "            display(HTML(f\"<div style='white-space:pre-wrap;'>{result['suggestions']}</div>\"))\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            display(HTML(f\"<p style='color:red;'>An error occurred: {e}</p>\"))\n",
        "        finally:\n",
        "            # Clean up the temporary files\n",
        "            if 'resume_path' in locals() and os.path.exists(resume_path):\n",
        "                os.remove(resume_path)\n",
        "            if 'jd_path' in locals() and os.path.exists(jd_path):\n",
        "                os.remove(jd_path)\n",
        "\n",
        "\n",
        "# Attach the button click event\n",
        "run_button.on_click(on_button_click)\n",
        "\n",
        "# Display the main layout\n",
        "display(main_layout)"
      ],
      "metadata": {
        "id": "skQIaa243Uxv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 761,
          "referenced_widgets": [
            "69109b2ec494458a9fe57b25590614b3",
            "e49ae7b2702547e1b5bcf131fd9c32f6",
            "7b25ba1bd9ba426ab968ccbafe4261c1",
            "a0bbfe40802e4145904bd437d42092b2",
            "53d40c2182534107bb8145af09e3e19e",
            "e1c01de9feca41edacd2c9b58fc0f457",
            "8c09c5b571c44b8185e94f9b28fd2936",
            "99d17571b1e744429e7cc2e28663b6dc",
            "2f2e8af27c5a4c2188bb3b18bfc72cec",
            "8c19b2d931f44683b91ec3ed2b17bbb3",
            "de340f3cf4c54d23847e68524c531600",
            "aff0aee360ff47689edb7ee2a0b297a6",
            "d4e737467e31454e8c736049852a4a26",
            "212729b3d084452c86e75f6d32f60a9a",
            "c4bb7bd61e5347d2a7b0440a8b5463ff",
            "c1a53f09a22b42b0b97f473860c82af7",
            "75ca5489ca354b818a615ee1e93b8aa2",
            "4901a8f0543247d786842f3ff70b74e2",
            "00bb44e7c0ad40dea6f9d4b6768f4af7",
            "cb1e9aa7f1e04f7a927cdbee42669ef2",
            "de4beec460474c21a902d363e366153b",
            "997538fee1344af78c7a8ff13cfd78d5",
            "dccf70f8f11842db80565002936ce2a8",
            "791f3fd50d7543d09e18fb3866e9ed46",
            "405867790bee434780fd147096b44c54",
            "faa83d98a0394b4bb9e5c72130dd8a94"
          ]
        },
        "outputId": "7fdb1361-97b2-4845-aedf-0bc94550e6ba"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<h2>âœ¨ Resume Relevance Checker</h2>'), VBox(children=(Label(value='Upload Files:'),â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69109b2ec494458a9fe57b25590614b3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the evaluation\n",
        "result = evaluate_resume_against_jd(resume_path, jd_path)\n",
        "\n",
        "# Display pretty results\n",
        "display_results(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "UZHepZ_j654m",
        "outputId": "8a35d9cf-56c6-49b2-c0c8-0448f6aa3be0"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Both `max_new_tokens` (=256) and `max_length`(=400) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hard score:  62.5\n",
            "Semantic score:  35.04\n",
            "Final score:  51.52  Verdict: Medium\n",
            "Missing required items: ['c', 'nlp', 'spark']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h2 style='color:#2E86C1'>ðŸ“Š Resume Relevance Evaluation Result</h2>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x120 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAACkCAYAAAAtxdExAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAFzhJREFUeJzt3XlUlNf9BvBnYIBhnUFkEQXEpbhgEwR3ghoXsFSr9piaYAqN0cQlwTaNsbFIYoJaa3Oi1dikRzG1GFONS6LmGCrW5dQVFRVFrYhYFUEti8EFme/vj/54k9cBYQiWG3k+58w5zL133nvnC8zDvHOZMYiIgIiISEEOzb0AIiKiujCkiIhIWQwpIiJSFkOKiIiUxZAiIiJlMaSIiEhZDCkiIlIWQ4qIiJTFkCIiImUxpKhOBQUFMBgMWLVq1SOdp3379khKSnqkcxDR9xNDqgVbtWoVDAZDrZdZs2Y19/Js3Lp1C6mpqQgPD4e7uzt8fHzw5JNPIjk5GVeuXGnu5TWJh31PioqKdGM//fRTTJgwAZ07d4bBYMCgQYPsmquueRYsWKAbt2HDBvzsZz9Dhw4d4ObmhrCwMLz22msoLS3VjRMRvP3222jbti38/PwwY8YM3Lt3Tzfm1q1baNu2LdasWWPXWqnlMjb3Aqj5zZ07F6Ghobq28PBwhISE4Pbt23BycmqmlX2jqqoKMTExyMvLQ2JiIl555RXcunULubm5WLNmDcaMGYPAwMDmXmaTqe17YrFYdNeXL1+O7Oxs9OrVCzdu3GjUPMOGDcPPf/5zXVtERITu+uTJkxEYGIgJEyYgODgYJ06cwNKlS7Ft2zYcOXIErq6uAICMjAzMmzcPb7zxBtzd3ZGWlgZ/f3/85je/0Y6VlpaG9u3b47nnnmvUeqnlYUgRRowYgaioqFr7TCbT/3g1tdu0aROOHj2KjIwMmwe4O3fu2PzF/ih9/fXXcHd3f6RzPOx7UmP16tVo27YtHBwcEB4e3qh5fvCDH2DChAkPHbN+/XqbZ2mRkZFITExERkYGXnzxRQDAli1bkJCQgLlz5wIAbt++jc8//1wLqfPnz2Px4sXYvXt3o9ZKLRNP91GdantNKikpCR4eHrh8+TJGjx4NDw8P+Pr64te//jWqq6t1t1+0aBH69+8PHx8fuLq6IjIyEuvXr2/UWs6fPw8AGDBggE2fyWSCl5eXri0vLw/PPPMMfH194erqirCwMMyePVs35ujRoxgxYgS8vLzg4eGBIUOGYP/+/boxNaffdu3ahalTp8LPzw/t2rXT+r/88ks89dRTcHd3h6enJ+Lj45Gbm6s7RlVVFfLy8nD16lW77nNFRYVNTb8tKCgIDg7f/Vf49u3buHPnTp39tZ1GHDNmDADg9OnTuuN4e3tr11u1aoXKykrt+muvvYbx48fXG75E38aQIpSVleH69eu6y8NUV1cjNjYWPj4+WLRoEQYOHIg//OEP+Oijj3TjFi9ejIiICMydOxfz5s2D0WjEuHHjsHXrVrvXGBISAgD4y1/+gvo+Xeb48ePo06cPsrKyMGnSJCxevBijR4/GF198oY3Jzc3FU089hZycHMycORMpKSm4cOECBg0ahAMHDtgcc+rUqTh16hTmzJmjvV63evVqxMfHw8PDA7/73e+QkpKCU6dOITo6GgUFBdptL1++jK5du+pOe9Vn8ODB8PLygpubG0aNGoVz5841+Lb2WLVqFdzd3eHq6opu3bo1+LWimtfHWrdurbX16tULn3zyCfbv348TJ07gww8/RO/evQEAmZmZyMrKwrx585r+TtDjTajFSk9PFwC1XkRELly4IAAkPT1du01iYqIAkLlz5+qOFRERIZGRkbq2yspK3fV79+5JeHi4PP3007r2kJAQSUxMfOhaKysrJSwsTABISEiIJCUlyYoVK+TatWs2Y2NiYsTT01MuXryoa7dardrXo0ePFmdnZzl//rzWduXKFfH09JSYmBitraZG0dHRcv/+fa29oqJCLBaLTJo0STdHUVGRmM1mXXtNHeu7jyIin376qSQlJcnHH38sGzdulN/+9rfi5uYmrVu3lsLCwjpv1717dxk4cGC9x/+2/v37y/vvvy+bN2+W5cuXS3h4uACQDz74oN7bTpw4URwdHeXs2bNaW3l5uURHR2s/Q927d5d///vfUlVVJd26dZMFCxbYtT4iERGGVAtW8wC8bNkyyczM1F1EHh5SxcXFumO9+uqr4u3tXedcN2/elJKSEpkyZYpYLBZdX0NCSkSktLRUXn/9dQkJCdEeCB0cHGT69Oly584dEREpLi4WAJKcnFznce7fvy9ubm7yzDPP2PS99NJL4uDgIGVlZSLyTY0+/vhj3bgNGzYIAMnKypKSkhLdZfjw4dKpU6d6709D7dmzRwwGg7z00kt1jmlMSD3o7t27Eh4eLhaLxeYPjG/LyMgQADJz5kybvurqasnNzZVjx45JVVWViIgsXrxYOnbsKHfv3pXc3FwZNGiQBAYGSkJCglZnorrwdB+hd+/eGDp0qO7yMCaTCb6+vro2b29v/Oc//9G1bdmyBX379oXJZEKrVq3g6+uL5cuXo6ysrFHrNJvNWLhwIQoKClBQUIAVK1YgLCwMS5cuxTvvvAMAyM/PB4CHbiQoKSlBZWUlwsLCbPq6du0Kq9WKS5cu6dof3GlXc/rt6aefhq+vr+7y1Vdfobi4uFH3sTbR0dHo06cP/v73vzfZMWvj7OyM6dOno7S0FNnZ2bWO2bNnDyZOnIjY2FikpaXZ9Ds4OKBbt2544oknYDQacf36dbz11ltYtGgRDAYDfvzjH6NHjx7YvHkzCgsL8corrzzS+0Tff9zdR3ZzdHSsd8yePXswatQoxMTE4IMPPkCbNm3g5OSE9PT0JvkfmZCQELzwwgsYM2YMOnTogIyMDLz77rvf+bh1qdlmXcNqtQL47+tSAQEBNuONxqb91QoKCsKZM2ea9Jh1zQMAN2/etOnLycnBqFGjEB4ejvXr1zfoPqakpKBnz54YPXo09uzZg6tXr2LhwoUwmUx4++23ERcXh/T09CbZAEKPJ4YUPRKfffYZTCYTtm/fDhcXF609PT29Sefx9vZGx44dcfLkSQBAhw4dAEC7XhtfX1+4ubnV+qCfl5cHBwcH7cG6Lh07dgQA+Pn51fvMsynk5+fbPHt9VPMAsJnr/PnziIuLg5+fH7Zt2wYPD496j5WTk4OVK1dqz8quXLkCb29v7d8aAgMDce/ePZSUlMDf37+J7wk9LvjnCz0Sjo6OMBgMui3UBQUF2LRpU6OOl5OTU+uuw4sXL+LUqVPaqTtfX1/ExMRg5cqVKCws1I2V/98V6OjoiOHDh2Pz5s26XXjXrl3DmjVrEB0dbbOl/UGxsbHw8vLCvHnzUFVVZdNfUlKifW3PFvRv367Gtm3bkJ2djbi4uHpvX5vKykrk5eXp6lfbPBUVFXj//ffRunVrREZGau1FRUUYPnw4HBwcsH379gaHZXJyMl588UXt1Ku/vz9KSkq0Z2mnT5+G0WjU7RAkehCfSdEjER8fj/feew9xcXF47rnnUFxcjGXLlqFTp044fvy43cfLzMxEamoqRo0ahb59+8LDwwP5+flYuXIl7t69i7feeksbu2TJEkRHR6Nnz56YPHkyQkNDUVBQgK1bt+LYsWMAgHfffReZmZmIjo7G1KlTYTQa8eGHH+Lu3btYuHBhvevx8vLC8uXL8fzzz6Nnz54YP348fH19UVhYiK1bt2LAgAFYunQpgG+2oCcmJtb7Poj9+/dHREQEoqKiYDabceTIEaxcuRJBQUF48803dWN3796t/WNsSUkJvv76a+2UZ0xMDGJiYgAABw8exODBg5GamqrVadmyZdi0aRNGjhyJ4OBgXL16VQv21atXw9nZWZsnLi4O+fn5mDlzJvbu3Yu9e/dqff7+/hg2bJjN/Vi3bh2OHz+Ozz77TGvr168f/P39MW7cOIwdOxaLFi3C2LFjG3T6mFqw5t65Qc2nZufaoUOHau2va3efu7u7zdjU1FR58MdpxYoV0rlzZ3FxcZEuXbpIenp6reMasrsvPz9f5syZI3379hU/Pz8xGo3i6+sr8fHxkpWVZTP+5MmTMmbMGLFYLGIymSQsLExSUlJ0Y44cOSKxsbHi4eEhbm5uMnjwYPnnP/+pG1NfjXbu3CmxsbFiNpvFZDJJx44dJSkpSQ4fPqyNsWcL+uzZs+XJJ58Us9ksTk5OEhwcLFOmTJGioiKbsTW1rO2SmpqqW+ODbV999ZUMGzZMAgICxMnJSSwWiwwfPlx27NhhM09dcwCodUdhZWWlhISEyJIlS2z6Dh06JD179hRPT08ZOXKkzS5RogcZROr5z0giIqJmwtekiIhIWQwpIiJSFkOKiIiUxZAiIiJlMaSIiEhZDCkiIlIWQ4qIiJTFkCIiImUxpIiISFkMKSIiUhZDioiIlMWQIiIiZTXqozqsViuuXLkCT09PGAyGpl4TERF9T4gIKioqEBgY+Eg+YblRIXXlypV6P7mUiIhajkuXLqFdu3ZNftxGhZSnpyeA/y6qvk8wJSKix1d5eTmCgoK0XGhqjQqpmlN8Xl5eDCkiInpkL/1w4wQRESmrUc+kNH8zA25NtBKix8lz/MBroqbAZ1JERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkLIYUEREpiyFFRETKMn6nWz9TBnh5NdFSiIiI9PhMioiIlMWQIiIiZTXqdJ+IAADKy8ubdDFERPT9UpMDNbnQ1BoVUjdu3AAABAUFNeliiIjo++nGjRswm81NftxGhVSrVq0AAIWFhY9kUY+r8vJyBAUF4dKlS/DihpMGYc0ah3WzH2vWOGVlZQgODtZyoak1KqQcHP77UpbZbOY3sxG8vLxYNzuxZo3DutmPNWucmlxo8uM+kqMSERE1AYYUEREpq1Eh5eLigtTUVLi4uDT1eh5rrJv9WLPGYd3sx5o1zqOum0Ee1b5BIiKi74in+4iISFkMKSIiUhZDioiIlMWQIiIiZTUqpJYtW4b27dvDZDKhT58+OHjwYFOv63tr/vz56NWrFzw9PeHn54fRo0fjzJkzujF37tzBtGnT4OPjAw8PD/z0pz/FtWvXmmnF6lmwYAEMBgNmzJihtbFmtbt8+TImTJgAHx8fuLq6okePHjh8+LDWLyKYM2cO2rRpA1dXVwwdOhTnzp1rxhU3v+rqaqSkpCA0NBSurq7o2LEj3nnnHd17z7X0uu3evRsjR45EYGAgDAYDNm3apOtvSH1u3ryJhIQEeHl5wWKxYOLEibh165b9ixE7rV27VpydnWXlypWSm5srkyZNEovFIteuXbP3UI+l2NhYSU9Pl5MnT8qxY8fkRz/6kQQHB8utW7e0MS+//LIEBQXJjh075PDhw9K3b1/p379/M65aHQcPHpT27dvLD3/4Q0lOTtbaWTNbN2/elJCQEElKSpIDBw5Ifn6+bN++Xf71r39pYxYsWCBms1k2bdokOTk5MmrUKAkNDZXbt28348qbV1pamvj4+MiWLVvkwoULsm7dOvHw8JDFixdrY1p63bZt2yazZ8+WDRs2CADZuHGjrr8h9YmLi5MnnnhC9u/fL3v27JFOnTrJs88+a/da7A6p3r17y7Rp07Tr1dXVEhgYKPPnz7d78paguLhYAMiuXbtERKS0tFScnJxk3bp12pjTp08LANm3b19zLVMJFRUV0rlzZ8nMzJSBAwdqIcWa1e6NN96Q6OjoOvutVqsEBATI73//e62ttLRUXFxc5JNPPvlfLFFJ8fHx8sILL+jaxo4dKwkJCSLCuj3owZBqSH1OnTolAOTQoUPamC+//FIMBoNcvnzZrvntOt137949ZGdnY+jQoVqbg4MDhg4din379tn/NK4FKCsrA/DNm/JmZ2ejqqpKV8MuXbogODi4xddw2rRpiI+P19UGYM3q8vnnnyMqKgrjxo2Dn58fIiIi8Oc//1nrv3DhAoqKinR1M5vN6NOnT4uuW//+/bFjxw6cPXsWAJCTk4O9e/dixIgRAFi3+jSkPvv27YPFYkFUVJQ2ZujQoXBwcMCBAwfsms+uN5i9fv06qqur4e/vr2v39/dHXl6eXRO3BFarFTNmzMCAAQMQHh4OACgqKoKzszMsFoturL+/P4qKipphlWpYu3Ytjhw5gkOHDtn0sWa1y8/Px/Lly/GrX/0Kb775Jg4dOoRXX30Vzs7OSExM1GpT2+9rS67brFmzUF5eji5dusDR0RHV1dVIS0tDQkICALBu9WhIfYqKiuDn56frNxqNaNWqld01bNS7oFPDTJs2DSdPnsTevXubeylKu3TpEpKTk5GZmQmTydTcy/nesFqtiIqKwrx58wAAEREROHnyJP70pz8hMTGxmVenrr/97W/IyMjAmjVr0L17dxw7dgwzZsxAYGAg66Ygu073tW7dGo6Ojja7qq5du4aAgIAmXdj33fTp07Flyxbs3LkT7dq109oDAgJw7949lJaW6sa35BpmZ2ejuLgYPXv2hNFohNFoxK5du7BkyRIYjUb4+/uzZrVo06YNunXrpmvr2rUrCgsLAUCrDX9f9V5//XXMmjUL48ePR48ePfD888/jl7/8JebPnw+AdatPQ+oTEBCA4uJiXf/9+/dx8+ZNu2toV0g5OzsjMjISO3bs0NqsVit27NiBfv362TXx40pEMH36dGzcuBFZWVkIDQ3V9UdGRsLJyUlXwzNnzqCwsLDF1nDIkCE4ceIEjh07pl2ioqKQkJCgfc2a2RowYIDNvzecPXsWISEhAIDQ0FAEBATo6lZeXo4DBw606LpVVlbafPaRo6MjrFYrANatPg2pT79+/VBaWors7GxtTFZWFqxWK/r06WPfhPbu9Fi7dq24uLjIqlWr5NSpUzJ58mSxWCxSVFRk76EeS1OmTBGz2Sz/+Mc/5OrVq9qlsrJSG/Pyyy9LcHCwZGVlyeHDh6Vfv37Sr1+/Zly1er69u0+ENavNwYMHxWg0Slpampw7d04yMjLEzc1N/vrXv2pjFixYIBaLRTZv3izHjx+Xn/zkJy1qK3VtEhMTpW3bttoW9A0bNkjr1q1l5syZ2piWXreKigo5evSoHD16VADIe++9J0ePHpWLFy+KSMPqExcXJxEREXLgwAHZu3evdO7c+X+zBV1E5I9//KMEBweLs7Oz9O7dW/bv39+YwzyWANR6SU9P18bcvn1bpk6dKt7e3uLm5iZjxoyRq1evNt+iFfRgSLFmtfviiy8kPDxcXFxcpEuXLvLRRx/p+q1Wq6SkpIi/v7+4uLjIkCFD5MyZM820WjWUl5dLcnKyBAcHi8lkkg4dOsjs2bPl7t272piWXredO3fW+jiWmJgoIg2rz40bN+TZZ58VDw8P8fLykl/84hdSUVFh91r4UR1ERKQsvncfEREpiyFFRETKYkgREZGyGFJERKQshhQRESmLIUVERMpiSBERkbIYUkREpCyGFBERKYshRUREymJIERGRshhSRESkrP8DyNUNPxz1FKgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div style=\"border:2px solid orange; padding:15px; border-radius:10px; background:#F8F9F9;\">\n",
              "        <h3>Final Verdict: <span style=\"color:orange;\">Medium</span></h3>\n",
              "        <p><b>Hard Match Score:</b> 62.5%</p>\n",
              "        <p><b>Semantic Similarity:</b> 35.04%</p>\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7a725e5d3290>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_05dda_row0_col0, #T_05dda_row1_col0, #T_05dda_row2_col0 {\n",
              "  background-color: #FADBD8;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_05dda\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_05dda_level0_col0\" class=\"col_heading level0 col0\" >ðŸš¨ Missing Required Skills</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_05dda_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_05dda_row0_col0\" class=\"data row0 col0\" >c</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_05dda_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_05dda_row1_col0\" class=\"data row1 col0\" >nlp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_05dda_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_05dda_row2_col0\" class=\"data row2 col0\" >spark</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<h3 style='color:#117A65'>ðŸ’¡ Suggested Improvements</h3>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div style='white-space:pre-wrap; background:#EBF5FB; padding:10px; border-radius:10px;'>Top missing skills/certifications (bullet list), and practical improvement actions the candidate can do in 30 / 90 days (bulleted), Job description: Detailed Job Descriptions for Walk-In Drive 1. Data Science Interns â€¢ Internship Duration: 6 months, followed by permanent employment based on performance â€¢ Bond: 2.6 years, including the internship period (total 30 months from joining) â€¢ Role Overview: â€¢ Work on data engineering, data visualization, and data science tasks. â€¢ Build deep learning models using Generative AI, Computer Vision, and NLP. â€¢ Apply ML and deep learning algorithms effectively. â€¢ Work with data visualization tools like Tableau or Power BI. â€¢ Perform data processing using Pandas and Spark. â€¢ Possess strong analytical and problem-solving skills. â€¢ Eligibility Criteria: â€¢ Qualification: B.Tech, BE â€¢ Batch Eligibility: 2023 and earlier pass-outs â€¢ Job Types: Full-time, Internship, Fresher, Permanent â€¢ Stipend: 5,000 per month â€¢ Schedule: Day shift, Monday to Friday â€¢ Location: Pune (Onsite) â€¢ Data Engineer â€¢ Location: Pune (Onsite) â€¢</div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok pdfplumber nltk spacy scikit-learn pandas numpy fuzzywuzzy python-docx\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eh2LwA7JajtR",
        "outputId": "36701adb-33ef-48e1-bd65-84059f80b6e0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.49.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.3.0)\n",
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.12/dist-packages (0.11.7)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.7)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: fuzzywuzzy in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: pdfminer.six==20250506 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (20250506)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (4.30.0)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.13)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.10)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.17.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.11.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (5.4.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.4.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.12/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.8.3)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.22.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.3.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3mâš  Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pdfplumber\n",
        "import spacy\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load SpaCy model once\n",
        "@st.cache_resource\n",
        "def load_spacy_model():\n",
        "    return spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "nlp = load_spacy_model()\n",
        "\n",
        "st.set_page_config(page_title=\"Resume Relevance Checker\", layout=\"wide\")\n",
        "\n",
        "st.title(\"ðŸ“Š Resume Relevance Dashboard\")\n",
        "\n",
        "# Sidebar for file uploads\n",
        "st.sidebar.header(\"Upload Files\")\n",
        "resume_file = st.sidebar.file_uploader(\"Upload Resume PDF\", type=\"pdf\")\n",
        "jd_file = st.sidebar.file_uploader(\"Upload Job Description PDF\", type=\"pdf\")\n",
        "\n",
        "# Function to extract text from PDF\n",
        "@st.cache_data\n",
        "def extract_pdf_text(file):\n",
        "    with pdfplumber.open(file) as pdf:\n",
        "        return \"\\n\".join(page.extract_text() for page in pdf.pages)\n",
        "\n",
        "# Process files\n",
        "if resume_file and jd_file:\n",
        "    resume_text = extract_pdf_text(resume_file)\n",
        "    jd_text = extract_pdf_text(jd_file)\n",
        "\n",
        "    # Show previews in tabs\n",
        "    tabs = st.tabs([\"Resume Preview\", \"JD Preview\", \"Skill Match\", \"Overall Score\"])\n",
        "\n",
        "    with tabs[0]:\n",
        "        st.subheader(\"Resume\")\n",
        "        st.text_area(\"Preview\", resume_text[:2000], height=300)\n",
        "\n",
        "    with tabs[1]:\n",
        "        st.subheader(\"Job Description\")\n",
        "        st.text_area(\"Preview\", jd_text[:2000], height=300)\n",
        "\n",
        "    with tabs[2]:\n",
        "        st.subheader(\"Skill Match\")\n",
        "        # Extract keywords (simple approach)\n",
        "        resume_words = set([token.text.lower() for token in nlp(resume_text) if token.is_alpha])\n",
        "        jd_words = set([token.text.lower() for token in nlp(jd_text) if token.is_alpha])\n",
        "        matched_skills = resume_words.intersection(jd_words)\n",
        "        st.metric(\"Matched Keywords\", len(matched_skills))\n",
        "        st.write(matched_skills)\n",
        "\n",
        "    with tabs[3]:\n",
        "        st.subheader(\"Overall Relevance Score\")\n",
        "        # Simple cosine similarity for overall match\n",
        "        vectorizer = TfidfVectorizer().fit([resume_text, jd_text])\n",
        "        vectors = vectorizer.transform([resume_text, jd_text])\n",
        "        score = cosine_similarity(vectors[0:1], vectors[1:2])[0][0]\n",
        "        st.metric(\"Relevance Score (%)\", f\"{score*100:.2f}\")"
      ],
      "metadata": {
        "id": "aGe_hfBKanFs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "875615c0-21f2-43b8-fd99-6302e9f52fd8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install streamlit -q"
      ],
      "metadata": {
        "id": "ra7PQhIebBqp"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pf41hmL7obM6",
        "outputId": "f27bf5ab-b815-4df6-d5fa-4624b01a4d00"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34.86.84.121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jWKljx8oi8P",
        "outputId": "fc5b2122-6f43-4eac-80d6-1a89593a6619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kâ §\u001b[1G\u001b[0Kâ ‡\u001b[1G\u001b[0Kâ \u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.86.84.121:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0Kâ ‹\u001b[1G\u001b[0Kâ ™\u001b[1G\u001b[0Kâ ¹\u001b[1G\u001b[0Kâ ¸\u001b[1G\u001b[0Kâ ¼\u001b[1G\u001b[0Kâ ´\u001b[1G\u001b[0Kâ ¦\u001b[1G\u001b[0Kyour url is: https://soft-hounds-kneel.loca.lt\n"
          ]
        }
      ]
    }
  ]
}